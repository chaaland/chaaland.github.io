---
title: "BKM"
categories:
  - Algorithms
date:   2025-04-01 12:30:00 +0100
mathjax: true
tags:
  - Numerical computing
toc: true
# classes: wide
excerpt: ""
header: 
  overlay_image: assets/bkm/images/splash_image.png
  overlay_filter: 0.2
---

In this article we'll explore yet another method for accurately calculating exponentials.
Similar in spirit to [CORDIC](../cordic), the Bajard-Kla-Muller (BKM) algorithm is a simple procedure that is friendly to hardware without floating point units (FPUs) as it involves only additions, multiplications, and bit-shifts.

- explain basic intuition of the algo as trying to build up the number
- show worked example for computing logarithm of pi
- explain how the method only works for numbers in a certain range
- explain how BKM can be used to compute the exponential

## Logarithmic BKM

We'll start with computing logarithms using the BKM algorithm in so-called _L_-mode.
The basic idea is to represent the number we want to compute the logarithm of as the product of other numbers.

$$
x = \prod_{k=0}^n a_k
$$

Using the property $$\log(ab) = \log(a) + \log(b)$$, we can compute the logarithm as

$$
\log x = \sum_{k=1}^n \log a_k
$$

At first glance, this seems to have made the problem worse.
Instead of computing the logarithm of a single number $$x$$, we now need to compute the logarithm of $$n$$ different numbers.

But the key idea behind the algorithm is that the set of unique values in the sequence will be drawn from a small handful of numbers. This allows us to compute values of $$\log a_k$$ offline (using some other method) and then look them up in a table as needed.

To see how this works in practice, it's best to illustrate with a concrete example.

Suppose we want to compute $$\log 3.14$$.
We start by initialising a variable $$x_{approx}=1$$.
We then multiply this by 2 to get $$x_{approx}=2$$.
Since this is below our desired value of $$x=3.14$$, we'll try increasing the value again but instead of doubling it, we'll multiply by 1.5.
This gives a new value of $$x_{approx}=3$$ which is still below the desired value.

We'll try increasing our value again, this time by a factor of 1.25 which gives $$x_{approx}=3.75$$.
Now our value is too large so we leave $$x_{approx}=3$$.
We then try multiplying by 1.125 which gives $$x_{approx} = 3.375$$.
This is still larger than our desired value of 3.14 so we skip this update as well.
Next we try multiplying by 1.0625 which gives $$x_{approx} = 3.1875$$, which is again too large.

The approximation can be concisely written as

$$
x = \prod_{k=0}^N (1+2^{-k})^{d_k}
$$

where $$d_k$$ depends on the particular input $$x$$.
Specifically, $$d_k$$ is 0 if $$a_k$$ is needed in the approximation of $$x$$ and 0 otherwise.
Given this equivalent expression for $$x$$, $$\log x$$ can be computed as

$$
\log x = \sum_{k=0}^N d_k \log(1+2^{-k})
$$

<figure class>
    <a href="/assets/bkm/images/log_pi.png"><img src="/assets/bkm/images/log_pi.png"></a>
    <figcaption>Figure 1: .</figcaption>
</figure>

### Worked Example

<!-- <figure class="half">
    <a href="/assets/cordic/images/circular_angle_01.png"><img src="/assets/cordic/images/circular_angle_01.png"></a>
    <a href="/assets/cordic/images/circular_angle_02.png"><img src="/assets/cordic/images/circular_angle_02.png"></a>
    <figcaption>Figure 8: Area of sectors for different theta.</figcaption>
</figure> -->

## Conclusion

## Footnotes

<a name="footnote1">1</a>: The determinant of the matrix is $$\cosh^2 \theta - \sinh^2 \theta = 1$$ meaning that areas are preserved. The matrix is _not_ orthogonal however so lengths of vectors are not preserved by the transformation.
